{
    parserClass="software.amazon.smithy.intellij.SmithyParser"
    parserUtilClass="software.amazon.smithy.intellij.SmithyParserUtil"
    extends="software.amazon.smithy.intellij.psi.impl.SmithyPsiElement"
    psiClassPrefix="Smithy"
    psiImplClassSuffix="Impl"
    psiPackage="software.amazon.smithy.intellij.psi"
    psiImplPackage="software.amazon.smithy.intellij.psi.impl"
    psiImplUtilClass="software.amazon.smithy.intellij.psi.impl.SmithyPsiImplUtil"
    elementTypeHolderClass="software.amazon.smithy.intellij.psi.SmithyTypes"
    elementTypeClass="software.amazon.smithy.intellij.SmithyElementType"
    tokenTypeClass="software.amazon.smithy.intellij.SmithyTokenType"
    //Note: some tokens have wrapper/alias rules for better AST generation, so all tokens have TOKEN_ to disambiguate within SmithyTypes
    tokens=[
        //Punctuation
        TOKEN_OPEN_PAREN="("
        TOKEN_CLOSE_PAREN=")"
        TOKEN_OPEN_BRACE="{"
        TOKEN_CLOSE_BRACE="}"
        TOKEN_OPEN_BRACKET="["
        TOKEN_CLOSE_BRACKET="]"
        TOKEN_COLON=":"
        TOKEN_COMMA=","
        TOKEN_EQUALS="="
        TOKEN_PERIOD="."
        TOKEN_DOLLAR_SIGN="$"
        TOKEN_AT="@"
        TOKEN_HASH="#"
        //Symbols (keywords (not reserved words), identifiers, object keys, etc.)
        TOKEN_APPLY="apply"
        TOKEN_USE="use"
        TOKEN_LIST="list"
        TOKEN_SET="set"
        TOKEN_MAP="map"
        TOKEN_METADATA="metadata"
        TOKEN_NAMESPACE="namespace"
        TOKEN_STRUCTURE="structure"
        TOKEN_UNION="union"
        TOKEN_SERVICE="service"
        TOKEN_OPERATION="operation"
        TOKEN_RESOURCE="resource"
        TOKEN_NULL="null"
        TOKEN_BOOLEAN="regexp:true|false"
        TOKEN_SIMPLE_TYPE_NAME="regexp:blob|boolean|document|string|byte|short|integer|long|float|double|bigInteger|bigDecimal|timestamp"
        TOKEN_SYMBOL="regexp:_*[A-Za-z][A-Za-z0-9_]*"
        //Literals
        TOKEN_NUMBER="regexp:-?(0|([1-9][0-9]*))(\.[0-9]+)?(e[+-]?[0-9]+)?"
        //Note: both string and text_block regex here permit invalid escape sequences to later on annotate them as errors
        TOKEN_STRING="regexp:\"((\\['bfnrt/\"\\])|(\\u[0-9A-Fa-f]{4})|(\\?[ !#-\[\]-\U10FFFF]))*\""
        TOKEN_TEXT_BLOCK="regexp:\"\"\"\n((\\['bfnrt/\"\\])|(\\u[0-9A-Fa-f]{4})|(\\?[ !#-\[\]-\U10FFFF])|(\\[\"]{3})|(\\?\r?\n))*\"\"\""
        //Note: since DOCUMENTATION_LINE can't include the trailing line-break, we need to explicitly match against an empty line comment or a non-empty line comment without the third leading slash (since the new-line matches more characters and would win when matching doc comment lines)
        TOKEN_LINE_COMMENT="regexp:((//)|(//[^/][\t -\U10FFFF]*))\r?\n"
        //Note: due to limitations with DocRenderPassFactory, documentation blocks cannot include the trailing line-break (otherwise it deems it invalid to render), so line-breaks are enforced within SmithySyntaxAnnotator
        TOKEN_DOCUMENTATION_LINE="regexp:///[\t -\U10FFFF]*"
        //Partial-match tokens for intermediate fallback states to avoid returning BAD_CHARACTER when quoted text is being typed out
        //see: https://intellij-support.jetbrains.com/hc/en-us/community/posts/360010554180--Custom-Language-Plugin-Highlighting-not-working-despite-correctly-parsed-psi-file
        TOKEN_INCOMPLETE_STRING="regexp:\"((\\['bfnrt/\"\\])|(\\u[0-9A-Fa-f]{4})|(\\?[ !#-\[\]-\U10FFFF]))+"
        TOKEN_INCOMPLETE_TEXT_BLOCK="regexp:\"\"\"\n((\\['bfnrt/\"\\])|(\\u[0-9A-Fa-f]{4})|(\\?[ !#-\[\]-\U10FFFF])|(\\[\"]{3})|(\\?\r?\n))+"
    ]
    implements("^(?!.*element).*")=element
    extends("array|object|primitive")=value
    extends("null|boolean|number|string|text_block|shape_id")=primitive
    extends("symbol|keyword|null|boolean|simple_type_name")=id
    extends("simple_shape|list|set|map|structure|union|service|operation|resource")=shape
}
//https://awslabs.github.io/smithy/1.0/spec/core/idl.html
root ::= model
model ::= control* metadata* [TOKEN_NAMESPACE namespace import* (applied_trait | shape)*] {methods=[getShapes control="" metadata="" namespace="" import="" applied_trait="" shape=""]}
control ::= TOKEN_DOLLAR_SIGN key TOKEN_COLON value
metadata ::= TOKEN_METADATA key TOKEN_EQUALS value
import ::= TOKEN_USE shape_id

//Shapes
shape ::= simple_shape | list | set | map | structure | union | service | operation | resource {methods=[getNamespace getName getDocumentation getDeclaredTraits]}
simple_shape ::= [documentation] trait* simple_type_name shape_name {methods=[getTypeName trait="" simple_type_name="" shape_name="" ]}
list ::= [documentation] trait* TOKEN_LIST shape_name members {methods=[trait="" shape_name="" members="member"]}
set ::= [documentation] trait* TOKEN_SET shape_name members {methods=[trait="" shape_name="" members="member"]}
map ::= [documentation] trait* TOKEN_MAP shape_name members {methods=[trait="" shape_name="" members="member"]}
structure ::= [documentation] trait* TOKEN_STRUCTURE shape_name members {methods=[trait="" shape_name="" members="member"]}
union ::= [documentation] trait* TOKEN_UNION shape_name members {methods=[trait="" shape_name="" members="member"]}
service ::= [documentation] trait* TOKEN_SERVICE shape_name object {methods=[trait="" shape_name="" body="object"]}
operation ::= [documentation] trait* TOKEN_OPERATION shape_name object {methods=[trait="" shape_name="" body="object"]}
resource ::= [documentation] trait* TOKEN_RESOURCE shape_name object {methods=[trait="" shape_name="" body="object"]}
private members ::= TOKEN_OPEN_BRACE [member (TOKEN_COMMA member)* [TOKEN_COMMA]] TOKEN_CLOSE_BRACE
member ::= [documentation] trait* member_name TOKEN_COLON shape_id {methods=[declared_traits="trait"]}

//Traits
applied_trait ::= TOKEN_APPLY shape_id trait
trait ::= TOKEN_AT shape_id [trait_arguments] {methods=[arguments="trait_arguments"]}
trait_arguments ::= TOKEN_OPEN_PAREN (trait_values | value) TOKEN_CLOSE_PAREN {methods=[values="trait_values"]}
trait_values ::= entry (TOKEN_COMMA entry)* [TOKEN_COMMA] {methods=[entries="entry"]}

//Node values
key ::= id | string
value ::= array | object | primitive
entry ::= key TOKEN_COLON value
array ::= TOKEN_OPEN_BRACKET [value (TOKEN_COMMA value)* [TOKEN_COMMA]] TOKEN_CLOSE_BRACKET {methods=[values="value"]}
object ::= TOKEN_OPEN_BRACE [entry (TOKEN_COMMA entry)* [TOKEN_COMMA]] TOKEN_CLOSE_BRACE {methods=[fields="entry"]}
primitive ::= null | boolean | number | string | text_block | shape_id

//Shape ID
shape_id ::= [namespace TOKEN_HASH] shape_name [TOKEN_DOLLAR_SIGN member_name] {methods=[toString]}
namespace ::= id (TOKEN_PERIOD id)* {methods=[toString parts="id"]}
shape_name ::= id {methods=[toString id=""]}
member_name ::= id {methods=[toString id=""]}
id ::= symbol | keyword | null | boolean | simple_type_name {methods=[toString null="" boolean=""]}

//Re-declared tokens which will receive a dedicated AST node instead of raw PsiElement (since they are used in a meaningful way, like as a variant within another AST node)
null ::= TOKEN_NULL {methods=[TOKEN_NULL=""]}
boolean ::= TOKEN_BOOLEAN {methods=[booleanValue TOKEN_BOOLEAN=""]}
number ::= TOKEN_NUMBER {methods=[byteValue shortValue intValue longValue floatValue doubleValue bigDecimalValue bigIntegerValue TOKEN_NUMBER=""]}
string ::= TOKEN_STRING {methods=[TOKEN_STRING=""]}
text_block ::= TOKEN_TEXT_BLOCK {methods=[TOKEN_TEXT_BLOCK=""]}
symbol ::= TOKEN_SYMBOL {methods=[TOKEN_SYMBOL=""]}
simple_type_name ::= TOKEN_SIMPLE_TYPE_NAME {methods=[TOKEN_SIMPLE_TYPE_NAME=""]}
keyword ::= TOKEN_APPLY | TOKEN_USE | TOKEN_LIST | TOKEN_SET | TOKEN_MAP | TOKEN_METADATA | TOKEN_NAMESPACE | TOKEN_STRUCTURE | TOKEN_UNION | TOKEN_SERVICE | TOKEN_OPERATION | TOKEN_RESOURCE
documentation ::= TOKEN_DOCUMENTATION_LINE+ {implements="com.intellij.psi.PsiDocCommentBase" methods=[getOwner getTokenType toDocString]}

//Fake rules (for introducing superinterfaces into the AST)
fake element ::=
